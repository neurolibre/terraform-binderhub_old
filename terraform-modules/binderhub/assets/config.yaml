#https://alan-turing-institute.github.io/hub23-deploy/advanced/optimising-jupyterhub.html#labelling-nodes-for-core-purpose
jupyterhub:
  ingress:
    enabled: true
    hosts:
      - ${domain}
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/tls-acme: "true"
      cert-manager.io/issuer: letsencrypt-staging
    https:
      enabled: true
      type: nginx
    config:
      # Allow POSTs of upto 64MB, for large notebook support.
      proxy-body-size: 64m
    tls:
      - secretName: ${TLS_name}-tls
        hosts:
          - ${domain}
  hub:
    baseUrl: /jupyter/
    image:
      name: ${docker_registry}/hub-image
      tag: v1.4
    extraVolumes:
    - name: shared-data
      hostPath:
        path: /DATA
    extraVolumeMounts:
    - name: shared-data
      mountPath: /srv/jupyterhub/data  # where hub can reach the shared data
    extraConfig:
      myExtraConfig: |
        import os
        import git
        import shutil
        import tempfile 
        import subprocess
        from repo2data.repo2data import Repo2Data
  
        async def my_pre_spawn_hook(spawner):
          repo_url = spawner.user_options.get('repo_url')
          ref = spawner.user_options.get('image').split(':')[-1]  # commit hash
          # Create temporary dir
          t = tempfile.mkdtemp()
          # Clone into temporary dir
          git.Repo.clone_from(repo_url, t, branch='master', depth=1)
          exists = os.path.isfile(os.path.join(t, 'binder/data_requirement.json'))
          exists = (exists and os.path.isfile(os.path.join(t, 'binder/requirements.txt')))
          if exists:
            # Copy desired file from temporary dir
            if os.path.isfile('data_requirement.json'):
              os.remove('data_requirement.json')
            if os.path.isfile('requirements.txt'):
              os.remove('requirements.txt')
            shutil.move(os.path.join(t, 'binder/data_requirement.json'), '.')
            shutil.move(os.path.join(t, 'binder/requirements.txt'), '.')
            Repo2Data(server=True).install()
            os.remove('requirements.txt')
            os.remove('data_requirement.json')
  
          # Remove temporary dir
          shutil.rmtree(t)
  
        c.KubeSpawner.pre_spawn_hook = my_pre_spawn_hook
  proxy:
    service:
      type: NodePort
  cull:
    timeout: 600
    every: 120
  singleuser:
    storage:
      extraVolumes:
      - name: shared-data
        hostPath:
          path: /DATA
      extraVolumeMounts:
      - name: shared-data
        mountPath: /home/jovyan/data  # where each user can reach shared data
        readOnly : true
    memory:
       guarantee: ${mem_alloc}G
    cpu:
       guarantee: ${cpu_alloc}

# BinderHub config
config:
  GitHubRepoProvider:
    banned_specs:
      - ^(?!neurolibre\/.*).*
      - ^ines/spacy-binder.*
      - ^soft4voip/rak.*
      - ^hmharshit/cn-ait.*
      - ^shishirchoudharygic/mltraining.*
      - ^hmharshit/mltraining.*
  BinderHub:
    hub_url: https://${domain}/jupyter
    use_registry: true
    image_prefix: ${docker_registry}/${domain}/binder-

service:
  type: NodePort

storage:
  capacity: 2G

ingress:
  enabled: true
  hosts:
    - ${domain}
  annotations:
    kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: "true"
    cert-manager.io/issuer: letsencrypt-staging
  https:
    enabled: true
    type: nginx
  config:
    # Allow POSTs of upto 64MB, for large notebook support.
    proxy-body-size: 64m
  tls:
    - secretName: ${TLS_name}-tls
      hosts: 
        - ${domain}
